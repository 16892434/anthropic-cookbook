{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to SQL with Claude\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Text to SQL is a natural language processing task that converts human-readable text queries into structured SQL queries. This lets users interact with databases using natural language. \n",
    "\n",
    "Claude can understand context, interpret complex queries, and generate accurate SQL statements. This guide focuses on using Claude to build a robust Text to SQL system.\n",
    "\n",
    "## Why is Text to SQL Useful?\n",
    "\n",
    "Text to SQL is valuable for several reasons:\n",
    "\n",
    "1. **Accessibility**: Non-technical users can query databases without knowing SQL syntax, making data access easier within organizations.\n",
    "\n",
    "2. **Efficiency**: Data analysts and scientists can quickly prototype queries using natural language.\n",
    "\n",
    "3. **Integration**: It enables more intuitive interfaces for database interactions in applications and chatbots.\n",
    "\n",
    "4. **Complex Query Generation**: LLMs can generate complex SQL queries involving multiple joins, subqueries, and aggregations, which can be time-consuming for humans to write.\n",
    "\n",
    "## What This Guide Covers\n",
    "\n",
    "This guide will walk you through building a Text to SQL system using LLMs. We'll cover:\n",
    "\n",
    "1. Setting up a test SQLite database\n",
    "2. Effective prompting for Text to SQL conversion\n",
    "3. RAG (Retrieval Augmented Generation) to handle more complex database systems\n",
    "4. Self-improvement and iteration of Claude's outputs\n",
    "5. Evaluations\n",
    "\n",
    "By the end of this guide, you'll understand how to implement and refine Text to SQL tasks using Claude, and have a framework for applying these techniques to your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Let's set up our environment and create a test SQLite database with two tables: `employees` and `departments`. We'll use this database throughout our guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q anthropic pandas voyageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from anthropic import Anthropic\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Set your Anthropic API key\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_ANTHROPIC_API_KEY\"\n",
    "os.environ[\"VOYAGE_API_KEY\"] = \"YOUR_VOYAGE_API_KEY\"\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = Anthropic()\n",
    "MODEL_NAME = \"claude-3-5-sonnet-20240620\"\n",
    "\n",
    "# Filepath to the SQLite database\n",
    "DATABASE_PATH = \"data/data.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new SQLite database and tables\n",
    "with sqlite3.connect(DATABASE_PATH) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.executescript('''\n",
    "    CREATE TABLE IF NOT EXISTS departments (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        location TEXT\n",
    "    );\n",
    "    CREATE TABLE IF NOT EXISTS employees (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        age INTEGER,\n",
    "        department_id INTEGER,\n",
    "        salary REAL,\n",
    "        hire_date DATE,\n",
    "        FOREIGN KEY (department_id) REFERENCES departments (id)\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "    # Insert sample data\n",
    "    cursor.executemany('INSERT OR REPLACE INTO departments VALUES (?,?,?)',\n",
    "        [(1, 'HR', 'New York'), (2, 'Engineering', 'San Francisco'), (3, 'Marketing', 'Chicago')])\n",
    "    \n",
    "    cursor.executemany('INSERT OR REPLACE INTO employees VALUES (?,?,?,?,?,?)',\n",
    "        [(1, 'John Doe', 30, 2, 75000.00, '2020-01-15'),\n",
    "         (2, 'Jane Smith', 35, 1, 65000.00, '2019-05-01'),\n",
    "         (3, 'Bob Johnson', 28, 2, 80000.00, '2021-03-10'),\n",
    "         (4, 'Alice Brown', 42, 3, 70000.00, '2018-11-20'),\n",
    "         (5, 'Charlie Davis', 31, 2, 85000.00, '2022-07-01')])\n",
    "\n",
    "    # Display table contents\n",
    "    for table in ['departments', 'employees']:\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM {table}\", conn)\n",
    "        print(f\"\\n{table.capitalize()} table:\")\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Basic Text to SQL Prompt\n",
    "\n",
    "Now that we have our database set up, let's create a basic prompt for Text to SQL conversion. A good prompt should include:\n",
    "\n",
    "1. Clear instructions for what we want the model to do\n",
    "2. The user's query\n",
    "3. The database's schema, so Claude knows how to translate the user's query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_info(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    schema_info = []\n",
    "    \n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    for (table_name,) in tables:\n",
    "        # Get columns for this table\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        table_info = f\"Table: {table_name}\\n\"\n",
    "        table_info += \"\\n\".join(f\"  - {col[1]} ({col[2]})\" for col in columns)\n",
    "        schema_info.append(table_info)\n",
    "    \n",
    "    conn.close()\n",
    "    return \"\\n\\n\".join(schema_info)\n",
    "\n",
    "# Get the schema info\n",
    "schema = get_schema_info(DATABASE_PATH)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our schema information, let's create a basic prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(schema, query):\n",
    "    return f\"\"\"\n",
    "        You are an AI assistant that converts natural language queries into SQL.\n",
    "        Given the following SQL database schema:\n",
    "\n",
    "        <schema>\n",
    "        {schema}\n",
    "        </schema>\n",
    "\n",
    "        Convert the following natural language query into SQL:\n",
    "        <query>\n",
    "        {query}\n",
    "        </query>\n",
    "\n",
    "        Provide only the SQL query in your response, without preamble or any explanation.\n",
    "    \"\"\"\n",
    "\n",
    "# Test the prompt\n",
    "user_query = \"What are the names of all employees in the Engineering department?\"\n",
    "prompt = generate_prompt(schema, user_query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this prompt with the Anthropic API to generate SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(prompt):\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "# Generate SQL\n",
    "sql = generate_sql(prompt)\n",
    "print(\"Generated SQL:\")\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our generated SQL by running it against our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(sql):\n",
    "    conn = sqlite3.connect(DATABASE_PATH)\n",
    "    result = pd.read_sql_query(sql, conn)\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "result = run_sql(sql)\n",
    "print(\"Query result:\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Prompt with Examples\n",
    "\n",
    "Our basic prompt works, but we can make it more effective by including examples. This technique, called few-shot learning, helps the model understand the task better by providing concrete examples of input-output pairs.\n",
    "\n",
    "Let's modify our `generate_prompt` function to include some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_with_examples(schema, query):\n",
    "    examples = \"\"\"\n",
    "        Example 1:\n",
    "        <query>List all employees in the HR department.</<query>\n",
    "        <output>SELECT e.name FROM employees e JOIN departments d ON e.department_id = d.id WHERE d.name = 'HR';</output>\n",
    "\n",
    "        Example 2:\n",
    "        User: What is the average salary of employees in the Engineering department?\n",
    "        SQL: SELECT AVG(e.salary) FROM employees e JOIN departments d ON e.department_id = d.id WHERE d.name = 'Engineering';\n",
    "\n",
    "        Example 3:\n",
    "        User: Who is the oldest employee?\n",
    "        SQL: SELECT name, age FROM employees ORDER BY age DESC LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"\"\"\n",
    "        You are an AI assistant that converts natural language queries into SQL.\n",
    "        Given the following SQL database schema:\n",
    "\n",
    "        <schema>\n",
    "        {schema}\n",
    "        </schema>\n",
    "\n",
    "        Here are some examples of natural language queries and their corresponding SQL:\n",
    "\n",
    "        <examples>\n",
    "        {examples}\n",
    "        </examples>\n",
    "\n",
    "        Now, convert the following natural language query into SQL:\n",
    "        <query>\n",
    "        {query}\n",
    "        </query>\n",
    "\n",
    "        Provide only the SQL query in your response, without preamble or any explanation.\n",
    "    \"\"\"\n",
    "\n",
    "# Test the new prompt\n",
    "user_query = \"What are the names and salaries of employees in the Marketing department?\"\n",
    "prompt = generate_prompt_with_examples(schema, user_query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this improved prompt to generate SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL using the improved prompt\n",
    "sql = generate_sql(prompt)\n",
    "print(\"Generated SQL:\")\n",
    "print(sql)\n",
    "\n",
    "# Run the generated SQL\n",
    "result = run_sql(sql)\n",
    "print(\"\\nQuery result:\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By including examples in our prompt, we've given the model a better understanding of how to structure its responses. This can lead to more accurate and consistent SQL generation, especially for more complex queries.\n",
    "\n",
    "In the next section, we'll explore how to handle more complex queries and improve the model's reasoning process using chain-of-thought prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-thought prompting encourages the model to break down complex problems into steps. For Text to SQL tasks, this can help with more complex queries that require multiple operations or careful consideration of the database schema.\n",
    "\n",
    "Let's modify our prompt to incorporate chain-of-thought reasoning using XML tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cot_prompt(schema, query):\n",
    "    examples = \"\"\"\n",
    "    <example>\n",
    "    <query>List all employees in the HR department.</query>\n",
    "    <thought_process>\n",
    "    1. We need to join the employees and departments tables.\n",
    "    2. We'll match employees.department_id with departments.id.\n",
    "    3. We'll filter for the HR department.\n",
    "    4. We only need to return the employee names.\n",
    "    </thought_process>\n",
    "    <sql>SELECT e.name FROM employees e JOIN departments d ON e.department_id = d.id WHERE d.name = 'HR';</sql>\n",
    "    </example>\n",
    "\n",
    "    <example>\n",
    "    <query>What is the average salary of employees hired in 2022?</query>\n",
    "    <thought_process>\n",
    "    1. We need to work with the employees table.\n",
    "    2. We need to filter for employees hired in 2022.\n",
    "    3. We'll use the YEAR function to extract the year from the hire_date.\n",
    "    4. We'll calculate the average of the salary column for the filtered rows.\n",
    "    </thought_process>\n",
    "    <sql>SELECT AVG(salary) FROM employees WHERE YEAR(hire_date) = 2022;</sql>\n",
    "    </example>\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"\"\"You are an AI assistant that converts natural language queries into SQL.\n",
    "    Given the following SQL database schema:\n",
    "\n",
    "    <schema>\n",
    "    {schema}\n",
    "    </schema>\n",
    "\n",
    "    Here are some examples of natural language queries, thought processes, and their corresponding SQL:\n",
    "\n",
    "    <examples>\n",
    "    {examples}\n",
    "    </examples>\n",
    "\n",
    "    Now, convert the following natural language query into SQL:\n",
    "    {query}\n",
    "\n",
    "    Within <thought_process> tags, explain your thought process for creating the SQL query.\n",
    "    Then, within <sql> tags, provide your output SQL query.\n",
    "    \"\"\"\n",
    "\n",
    "# Test the new prompt\n",
    "user_query = \"What are the names and hire dates of employees in the Engineering department, ordered by their salary?\"\n",
    "prompt = generate_cot_prompt(schema, user_query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this chain-of-thought prompt with XML tags to generate SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_with_explanation(prompt):\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "# Generate SQL using the chain-of-thought prompt\n",
    "result = generate_sql_with_explanation(prompt)\n",
    "print(\"Raw response from Claude:\")\n",
    "print(result)\n",
    "\n",
    "# Extract thought process and SQL query using simple string manipulation\n",
    "# Note: For more robust parsing, consider using an XML parsing library\n",
    "thought_process = result.split('<thought_process>')[1].split('</thought_process>')[0].strip()\n",
    "sql = result.split('<sql>')[1].split('</sql>')[0].strip()\n",
    "\n",
    "print(\"\\nThought Process:\")\n",
    "print(thought_process)\n",
    "\n",
    "print(\"\\nGenerated SQL:\")\n",
    "print(sql)\n",
    "\n",
    "# Run the generated SQL\n",
    "query_result = run_sql(sql)\n",
    "print(\"\\nQuery result:\")\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing RAG for Complex Database Schemas\n",
    "\n",
    "As databases grow larger and more complex, providing the entire schema in each prompt becomes impractical. Retrieval Augmented Generation (RAG) can help us manage this complexity by dynamically retrieving relevant schema information based on the user's query.\n",
    "\n",
    "First, we will build a simple VectorDB class that leverages the embedding models created by VoyageAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import voyageai\n",
    "import pickle\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, db_path='./data/vector_db.pkl'):\n",
    "        self.client = voyageai.Client(api_key=os.getenv(\"VOYAGE_API_KEY\"))\n",
    "        self.db_path = db_path\n",
    "        self.load_db()\n",
    "\n",
    "    def load_db(self):\n",
    "        if os.path.exists(self.db_path):\n",
    "            with open(self.db_path, \"rb\") as file:\n",
    "                data = pickle.load(file)\n",
    "            self.embeddings, self.metadata, self.query_cache = data['embeddings'], data['metadata'], json.loads(data['query_cache'])\n",
    "        else:\n",
    "            self.embeddings, self.metadata, self.query_cache = [], [], {}\n",
    "\n",
    "    def load_data(self, data):\n",
    "        if not self.embeddings:\n",
    "                texts = [item[\"text\"] for item in data]\n",
    "                self.embeddings = [emb for batch in range(0, len(texts), 128) \n",
    "                                    for emb in self.client.embed(texts[batch:batch+128], model=\"voyage-2\").embeddings]\n",
    "                self.metadata = [item[\"metadata\"] for item in data]  # Store only the inner metadata\n",
    "                self.save_db()\n",
    "\n",
    "    def search(self, query, k=5, similarity_threshold=0.3):\n",
    "        if query not in self.query_cache:\n",
    "            self.query_cache[query] = self.client.embed([query], model=\"voyage-2\").embeddings[0]\n",
    "            self.save_db()\n",
    "        \n",
    "        similarities = np.dot(self.embeddings, self.query_cache[query])\n",
    "        top_indices = np.argsort(similarities)[::-1]\n",
    "        \n",
    "        return [{\"metadata\": self.metadata[i], \"similarity\": similarities[i]} \n",
    "                for i in top_indices if similarities[i] >= similarity_threshold][:k]\n",
    "\n",
    "    def save_db(self):\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump({\"embeddings\": self.embeddings, \"metadata\": self.metadata, \n",
    "                         \"query_cache\": json.dumps(self.query_cache)}, file)\n",
    "\n",
    "# Initialize and load schema data\n",
    "vectordb = VectorDB()\n",
    "if not vectordb.embeddings:\n",
    "    with sqlite3.connect(DATABASE_PATH) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        schema_data = [\n",
    "            {\"text\": f\"Table: {table[0]}, Column: {col[1]}, Type: {col[2]}\", \n",
    "             \"metadata\": {\"table\": table[0], \"column\": col[1], \"type\": col[2]}}\n",
    "            for table in cursor.fetchall()\n",
    "            for col in cursor.execute(f\"PRAGMA table_info({table[0]})\").fetchall()\n",
    "        ]\n",
    "    vectordb.load_data(schema_data)\n",
    "\n",
    "# Test the search functionality\n",
    "test_query = \"What is the average salary of employees in each department?\"\n",
    "results = vectordb.search(test_query)\n",
    "print(\"Search results:\")\n",
    "for result in results:\n",
    "    print(f\"Similarity: {result['similarity']}, Metadata: {result['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's update our prompt generation function to use RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_prompt(query):\n",
    "    relevant_schema = vectordb.search(query, k=10, similarity_threshold=0.3)\n",
    "    schema_info = \"\\n\".join([f\"Table: {item['metadata']['table']}, Column: {item['metadata']['column']}, Type: {item['metadata']['type']}\" \n",
    "                             for item in relevant_schema])\n",
    "    \n",
    "    return f\"\"\"You are an AI assistant that converts natural language queries into SQL.\n",
    "    Given the following relevant columns from the SQL database schema:\n",
    "\n",
    "    <schema>\n",
    "    {schema_info}\n",
    "    </schema>\n",
    "\n",
    "    Convert the following natural language query into SQL:\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    Within <thought_process> tags, explain your thought process for creating the SQL query.\n",
    "    Then, within <sql> tags, provide your output SQL query.\n",
    "    \"\"\"\n",
    "\n",
    "# Test the RAG-based prompt\n",
    "user_query = \"What is the average salary of employees in each department?\"\n",
    "prompt = generate_rag_prompt(user_query)\n",
    "print(\"Generated prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "# Generate and execute SQL\n",
    "result = generate_sql_with_explanation(prompt)\n",
    "print(\"\\nGenerated result:\")\n",
    "print(result)\n",
    "\n",
    "# Extract and run the SQL query\n",
    "sql = result.split('<sql>')[1].split('</sql>')[0].strip()\n",
    "print(\"\\nExtracted SQL:\")\n",
    "print(sql)\n",
    "\n",
    "query_result = run_sql(sql)\n",
    "print(\"\\nQuery result:\")\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RAG in our Text to SQL system offers several advantages:\n",
    "\n",
    "1. Scalability: It allows us to handle much larger and more complex database schemas without overwhelming the model with unnecessary information.\n",
    "\n",
    "2. Relevance: By providing only the most relevant parts of the schema, we help the model focus on the information it needs to generate the correct SQL query.\n",
    "\n",
    "3. Flexibility: The system can adapt to changes in the database schema without requiring updates to the prompt template.\n",
    "\n",
    "4. Efficiency: It can potentially reduce token usage and improve response times, especially for large databases.\n",
    "\n",
    "However, it's important to note that this approach also has some limitations:\n",
    "\n",
    "1. Dependency on embedding quality: The effectiveness of RAG depends on the quality of the embeddings and the relevance calculation.\n",
    "\n",
    "2. Potential for missing context: There's a risk that some relevant schema information might not be retrieved, leading to incomplete or incorrect queries.\n",
    "\n",
    "3. Complexity: Implementing RAG adds another layer of complexity to the system, which may not be necessary for smaller, simpler databases.\n",
    "\n",
    "In the next section, we'll explore how to implement a REPL (Read-Eval-Print Loop) for interactive query refinement and error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Query Self-Improvement\n",
    "\n",
    "Here, we'll build a self-improvement loop with Claude. This lets Claude execute the SQL it generates, analyze the results or errors, and improve the query if necessary.\n",
    "\n",
    "This technique helps with:\n",
    "\n",
    "1. Error Handling: It can catch and respond to SQL syntax errors or other execution issues.\n",
    "2. Iterative Refinement: The model can learn from its mistakes and thought processes, and improve its output.\n",
    "3. Performance: It increases the likelihood of generating a valid and executable SQL query.\n",
    "\n",
    "In practice, you might want to adjust the `max_attempts` value based on your specific use case and performance requirements.\n",
    "\n",
    "Let's start by creating a function that tries to execute the SQL and provides feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_with_feedback(sql):\n",
    "    try:\n",
    "        result = run_sql(sql)\n",
    "        return True, result, \"Query executed successfully.\"\n",
    "    except Exception as e:\n",
    "        return False, None, str(e)\n",
    "\n",
    "def self_improving_sql_generation(query, max_attempts=3):\n",
    "    feedback = None\n",
    "    sql = None\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        if attempt == 0:\n",
    "            prompt = generate_rag_prompt(query)\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "            The previous SQL query resulted in this error: {feedback}\n",
    "            Analyze the error and provide an improved SQL query.\n",
    "            Original query: {sql}\n",
    "            Explain your changes in <thought_process> tags and provide the corrected SQL in <sql> tags.\n",
    "            \"\"\"\n",
    "        \n",
    "        response = generate_sql_with_explanation(prompt)\n",
    "        sql = response.split('<sql>')[1].split('</sql>')[0].strip()\n",
    "        \n",
    "        print(f\"\\nAttempt {attempt + 1}:\")\n",
    "        \n",
    "        success, result, feedback = execute_sql_with_feedback(sql)\n",
    "        if success:\n",
    "            print(\"SQL executed successfully!\")\n",
    "            return sql, result\n",
    "        else:\n",
    "            print(\"SQL failed to execute\")\n",
    "\n",
    "    print(\"Maximum attempts reached. Could not generate a valid SQL query.\")\n",
    "    return None, None\n",
    "\n",
    "# Test the self-improving SQL generation\n",
    "user_query = \"For each department, show the ratio of the highest paid employee's salary to the lowest paid employee's salary, but only for departments where this ratio is greater than 3.\"\n",
    "final_sql, result = self_improving_sql_generation(user_query)\n",
    "\n",
    "if final_sql:\n",
    "    print(\"\\nFinal SQL query:\")\n",
    "    print(final_sql)\n",
    "    print(\"\\nQuery result:\")\n",
    "    display(result)\n",
    "else:\n",
    "    print(\"Failed to generate a valid SQL query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This self-improvement loop makes our Text to SQL system far more reliable for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations\n",
    "\n",
    "Evaluating Text to SQL systems isn't always straightforward. A SQL query might be written correctly but not give the right answer, or it might work but not be the best way to get the result. Some queries are simple and easy to generate, while others are very complex.\n",
    "\n",
    "Here, we'll explore building an evaluation framework using [Promptfoo](https://promptfoo.dev), an open source LLM evaluation toolkit. To get started,check out `./evaluation/README.md`.\n",
    "\n",
    "When you've successfully run an evaluation come back here to view the results. You can also render these results via the command `npx promptfoo@latest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
